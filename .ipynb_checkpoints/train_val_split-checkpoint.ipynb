{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat, savemat\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.json and val.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(np.arange(17503), test_size=0.1, random_state=42)\n",
    "test.sort()\n",
    "train.sort()\n",
    "\n",
    "dct = {}\n",
    "lst = []\n",
    "for x in test:\n",
    "    dct[x] = 0\n",
    "for x in train:\n",
    "    dct[x] = 1\n",
    "for x in sorted(dct):\n",
    "    lst.append(dct[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17503"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type here what part you want to generate and path to folder with images. Also set True COCO_bboxes if you have COCO detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = 'train' #or \"val\"\n",
    "path_to_images = '/home/olga/CenterNet/data/coco/images/'\n",
    "COCO_bboxes = True\n",
    "if COCO_bboxes == True:\n",
    "    dataCOCO = json.load(open(\"results.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_file = json.load(open('mpii_human_pose_v1_u12_1.json', 'r'))['RELEASE'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24987"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_file['annolist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': [2], 'x': [987], 'y': [607], 'is_visible': '1'},\n",
       " {'id': [3], 'x': [1194], 'y': [571], 'is_visible': '1'},\n",
       " {'id': [6], 'x': [1091], 'y': [589], 'is_visible': '1'},\n",
       " {'id': [7], 'x': [1038], 'y': [292], 'is_visible': '1'},\n",
       " {'id': [8], 'x': [1025], 'y': [261], 'is_visible': []},\n",
       " {'id': [9], 'x': [947], 'y': [74], 'is_visible': []},\n",
       " {'id': [10], 'x': [914], 'y': [539], 'is_visible': '0'},\n",
       " {'id': [11], 'x': [955], 'y': [470], 'is_visible': '1'},\n",
       " {'id': [12], 'x': [931], 'y': [315], 'is_visible': '1'},\n",
       " {'id': [13], 'x': [1145], 'y': [269], 'is_visible': '1'},\n",
       " {'id': [14], 'x': [1226], 'y': [475], 'is_visible': '1'},\n",
       " {'id': [15], 'x': [1096], 'y': [433], 'is_visible': '1'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_file['annolist'][5]['annorect'][1]['annopoints'][0]['point']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are needed for annotations with COCO boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def choose_best_prediction(gtFrame, prFrames): # list, list of lists\n",
    "    bestIoUscore = 0.\n",
    "    bestIoU = [0, 0, 0, 0]\n",
    "    for i in range(len(prFrames)):\n",
    "        score =  bb_intersection_over_union(gtFrame, prFrames[i])\n",
    "        if score > bestIoUscore:\n",
    "            bestIoUscore = score\n",
    "            bestIoU = prFrames[i]\n",
    "    return bestIoU\n",
    "\n",
    "def choose_all_good_predictions(gtFrame, prFrames): # list, list of lists\n",
    "    IoUs = []\n",
    "    for i in range(len(prFrames)):\n",
    "        if bb_intersection_over_union(gtFrame, prFrames[i]) >= 0.5:\n",
    "            IoUs.append(prFrames[i])\n",
    "    return IoUs\n",
    "\n",
    "def unite(COCObbox, MPIIbbox):\n",
    "    xA = min(COCObbox[0], MPIIbbox[0])\n",
    "    yA = min(COCObbox[1], MPIIbbox[1])\n",
    "    xB = max(COCObbox[2], MPIIbbox[2])\n",
    "    yB = max(COCObbox[3], MPIIbbox[3])\n",
    "    \n",
    "    return [xA, yA, xB, yB]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty(list,name):\n",
    "    \n",
    "    try:\n",
    "        list[name]\n",
    "    except ValueError:\n",
    "        return True\n",
    "\n",
    "    if len(list[name]) > 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "save_path = db_type + '.json'\n",
    "\n",
    "joint_num = 16\n",
    "img_num = len(annot_file['annolist'])\n",
    "\n",
    "aid = 0\n",
    "counter = -1\n",
    "coco = {'images': [], 'categories': [], 'annotations': []}\n",
    "for img_id in range(img_num):\n",
    "  \n",
    "    if (annot_file['img_train'][img_id] == 0):\n",
    "        continue\n",
    "    \n",
    "    if ((db_type == 'train' and annot_file['img_train'][img_id] == 1) ) and \\\n",
    "        check_empty(annot_file['annolist'][img_id],'annorect') == False: #any person is annotated\n",
    "        counter+=1\n",
    "        if db_type == 'train' and lst[counter] == 0:\n",
    "            continue\n",
    "        \n",
    "        if db_type == 'val' and lst[counter] == 1: \n",
    "            continue\n",
    "    \n",
    "        filename = path_to_images + str(annot_file['annolist'][img_id]['image'][0]['name']) #filename\n",
    "        img = Image.open(filename)\n",
    "        w,h = img.size\n",
    "        img_dict = {'id': img_id, 'file_name': filename, 'width': w, 'height': h}\n",
    "        coco['images'].append(img_dict)\n",
    "\n",
    "        if db_type == 'test':\n",
    "            continue\n",
    "        \n",
    "        person_num = len(annot_file['annolist'][img_id]['annorect']) #person_num\n",
    "        joint_annotated = np.zeros((person_num,joint_num))\n",
    "        if COCO_bboxes == True:\n",
    "            prFrames = [item['bbox'] for item in dataCOCO[str(img_id)]]\n",
    "\n",
    "        for pid in range(person_num):\n",
    "            \n",
    "            if 'annopoints' in annot_file['annolist'][img_id]['annorect'][pid] and \\\n",
    "                len(annot_file['annolist'][img_id]['annorect'][pid]['annopoints']) > 0: #kps is annotated\n",
    "                \n",
    "                bbox = np.zeros((4)) # xmin, ymin, w, h\n",
    "                kps = np.zeros((joint_num,3)) # xcoord, ycoord, vis\n",
    "\n",
    "                #kps\n",
    "                annot_joint_num = len(annot_file['annolist'][img_id]['annorect'][pid]['annopoints'][0]['point'])\n",
    "                for jid in range(annot_joint_num):\n",
    "                    annot_jid = annot_file['annolist'][img_id]['annorect'][pid]['annopoints'][0]['point'][jid]['id'][0]\n",
    "                    kps[annot_jid][0] = annot_file['annolist'][img_id]['annorect'][pid]['annopoints'][0]['point'][jid]['x'][0]\n",
    "                    kps[annot_jid][1] = annot_file['annolist'][img_id]['annorect'][pid]['annopoints'][0]['point'][jid]['y'][0]\n",
    "                    kps[annot_jid][2] = 2\n",
    "                \n",
    "                \n",
    "                \n",
    "                keypoint_list = kps.reshape(-1).tolist()\n",
    "                xmax = 0\n",
    "                ymax = 0\n",
    "                xmin = 10000\n",
    "                ymin = 10000\n",
    "                for i in range(16):\n",
    "                    if (keypoint_list[i*3] < 0 or keypoint_list[i*3+1] < 0 or keypoint_list[i*3] > w or keypoint_list[i*3+1] > h):\n",
    "                        keypoint_list[i*3]=0\n",
    "                        keypoint_list[i*3+1]=0\n",
    "                        keypoint_list[i*3+2]=0\n",
    "                    else:\n",
    "                        if (keypoint_list[i*3] > xmax):\n",
    "                            xmax = keypoint_list[i*3] \n",
    "                        if (keypoint_list[i*3] < xmin):\n",
    "                            xmin = keypoint_list[i*3] \n",
    "                        if (keypoint_list[i*3+1] > ymax):\n",
    "                            ymax = keypoint_list[i*3+1] \n",
    "                        if (keypoint_list[i*3+1] < ymin):\n",
    "                            ymin = keypoint_list[i*3+1] \n",
    "                \n",
    "                gt = [xmin, ymin, xmax, ymax]\n",
    "                \n",
    "                if COCO_bboxes == True:\n",
    "                    #prBest = choose_best_prediction(gt.copy(), prFrames.copy())\n",
    "                    #if bb_intersection_over_union(gt.copy(), prBest.copy()) >= 0.5:\n",
    "                    #    gt = unite(gt.copy(), prBest.copy())\n",
    "\n",
    "                    preds = choose_all_good_predictions(gt.copy(), prFrames.copy())\n",
    "                    for pred in preds:\n",
    "                        gt = unite(gt.copy(), pred.copy())\n",
    "                \n",
    "                width = gt[2] - gt[0]\n",
    "                height = gt[3] - gt[1]\n",
    "                # corrupted bounding box\n",
    "                if width <= 0 or height <= 0:\n",
    "                    continue\n",
    "                # 20% extend    \n",
    "                else:\n",
    "                    bbox[0] = max(0, gt[0])\n",
    "                    bbox[1] = max(0, gt[1])\n",
    "                    bbox[2] = width\n",
    "                    bbox[3] = height\n",
    "  \n",
    "                        \n",
    "               # keypoint_list = changeOrderkpl(keypoint_list)\n",
    "                person_dict = {'num_keypoints': int(np.sum(kps[:,2]==2)),'area': bbox[2]*bbox[3],'iscrowd': 0, 'keypoints': keypoint_list, 'image_id': img_id,'bbox': bbox.tolist(), 'category_id': 1, 'id': aid  }\n",
    "                coco['annotations'].append(person_dict)\n",
    "                aid += 1\n",
    "\n",
    "category = {\n",
    "    \"supercategory\": \"person\",\n",
    "    \"id\": 1,  # to be same as COCO, not using 0\n",
    "    \"name\": \"person\",\n",
    "    \"skeleton\": [[0,1],\n",
    "        [1,2], \n",
    "        [2,6], \n",
    "        [7,12], \n",
    "        [12,11], \n",
    "        [11,10], \n",
    "        [5,4], \n",
    "        [4,3], \n",
    "        [3,6], \n",
    "        [7,13], \n",
    "        [13,14], \n",
    "        [14,15], \n",
    "        [6,7], \n",
    "        [7,8], \n",
    "        [8,9]] ,\n",
    "    \"keypoints\": [\"r_ankle\", \"r_knee\",\"r_hip\", \n",
    "                    \"l_hip\", \"l_knee\", \"l_ankle\",\n",
    "                  \"pelvis\", \"throax\",\n",
    "                  \"upper_neck\", \"head_top\",\n",
    "                  \"r_wrist\", \"r_elbow\", \"r_shoulder\",\n",
    "                  \"l_shoulder\", \"l_elbow\", \"l_wrist\"]}\n",
    "\n",
    "coco['categories'] = [category]\n",
    "\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(coco, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15752\n"
     ]
    }
   ],
   "source": [
    "json_file = open('train.json') \n",
    "data = json.load(json_file)\n",
    "print(len(data['images']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotations for single-person task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_file_mat = loadmat('mpii_human_pose_v1_u12_1')['RELEASE']\n",
    "single_person = []\n",
    "for imgidx in range(len(annot_file_mat['single_person'][0][0])):\n",
    "    single_person.append([])\n",
    "    if len(annot_file_mat['single_person'][0][0][imgidx][0]) > 0:\n",
    "        if len(annot_file_mat['single_person'][0][0][imgidx][0][0]) > 0:\n",
    "            for num in range(len(annot_file_mat['single_person'][0][0][imgidx][0])):  \n",
    "                single_person[imgidx].append(annot_file_mat['single_person'][0][0][imgidx][0][num][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annot_file = loadmat('mpii_human_pose_v1_u12_1')['RELEASE']\n",
    "save_path = db_type + '.json'\n",
    "\n",
    "joint_num = 16\n",
    "img_num = len(annot_file['annolist'])\n",
    "\n",
    "aid = 0\n",
    "counter = -1\n",
    "lst_val = []\n",
    "inds = []\n",
    "annorect = {}\n",
    "lst_single_person = []\n",
    "count_img = 0\n",
    "\n",
    "for img_id in range(img_num):\n",
    "   # print(img_id)\n",
    "    \n",
    "    if (annot_file['img_train'][img_id] == 0):\n",
    "        continue\n",
    "    \n",
    "    if db_type == 'test':\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    if ((db_type == 'train' and annot_file['img_train'][img_id] == 1) ) and \\\n",
    "        check_empty(annot_file['annolist'][img_id],'annorect') == False: #any person is annotated\n",
    "        counter+=1\n",
    "        if db_type == 'train' and lst[counter] == 0:\n",
    "            continue\n",
    "        \n",
    "        if db_type == 'val' and lst[counter] == 1: \n",
    "            continue\n",
    "            \n",
    "        count_img+=1\n",
    "        \n",
    "        filename = path_to_images + str(annot_file['annolist'][img_id]['image'][0]['name']) #filename\n",
    "        img = Image.open(filename)\n",
    "        w,h = img.size\n",
    "        single = []\n",
    "        person_ = False\n",
    "        for i in single_person[img_id]:\n",
    "            person = annot_file['annolist'][img_id]['annorect'][i-1]\n",
    "            if 'annopoints' in person:\n",
    "                #person_ = True\n",
    "                lst_points = []\n",
    "                for j in range(len(person['annopoints'][0]['point'])):\n",
    "                    point = person['annopoints'][0]['point'][j]\n",
    "                    if point['x'][0] < 0 or point['y'][0] < 0 or point['x'][0] > w or point['y'][0] > h:\n",
    "                        continue\n",
    "                    lst_points.append(point)\n",
    "                person['annopoints'][0]['point'] = lst_points\n",
    "                if len(person['annopoints'][0]['point']) > 0:\n",
    "                    single.append(person)\n",
    "        if len(single) > 0:\n",
    "            lst_single_person.append({'image':annot_file['annolist'][img_id]['image'], 'annorect' : single})\n",
    "            inds.append(img_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13727"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_single_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inds, file=open(db_type + '_single_inds.txt', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump({'annolist': lst_single_person}, open(db_type + '_single.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotations for multi-person task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = json.load(open('groups.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = db_type+'.json'\n",
    "\n",
    "joint_num = 16\n",
    "img_num = len(annot_file['annolist'])\n",
    "\n",
    "aid = 0\n",
    "counter = -1\n",
    "lst_val = []\n",
    "new_groups = []\n",
    "ids = []\n",
    "\n",
    "for img_id in range(img_num):\n",
    "   # print(img_id)\n",
    "    \n",
    "    if (annot_file['img_train'][img_id] == 0):\n",
    "        continue\n",
    "    \n",
    "    if ((db_type == 'train' and annot_file['img_train'][img_id] == 1) ) and \\\n",
    "        check_empty(annot_file['annolist'][img_id],'annorect') == False: #any person is annotated\n",
    "        counter+=1\n",
    "        if db_type == 'train' and lst[counter] == 0:\n",
    "            continue\n",
    "        \n",
    "        if db_type == 'val' and lst[counter] == 1: \n",
    "            continue\n",
    "        lst_val.append(annot_file['annolist'][img_id])\n",
    "        new_groups.append(groups['groups'][0][img_id])\n",
    "        ids.append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_multi = np.zeros(len(new_groups))\n",
    "for i in range(len(new_groups)):\n",
    "    for j in range(len(new_groups[i])):\n",
    "        if len(new_groups[i][j]) > 1:\n",
    "            is_multi[i] = 1\n",
    "ans_list = []\n",
    "for i in range(len(lst_val)):\n",
    "    if is_multi[i]:\n",
    "        ans_list.append(lst_val[i])\n",
    "        \n",
    "for image in ans_list:\n",
    "    filename = path_to_images + image['image'][0]['name']\n",
    "    img = Image.open(filename)\n",
    "    w,h = img.size\n",
    "    for person in image['annorect']:\n",
    "        lst = []\n",
    "        counter = 0\n",
    "        if len(person['annopoints']) == 0:\n",
    "            continue\n",
    "        for point in person['annopoints'][0]['point']:\n",
    "            if point['x'][0] < 0 or point['x'][0] > w or point['y'][0] < 0 or point['y'][0] > h:\n",
    "                lst.append(counter)\n",
    "            counter+=1\n",
    "        for num in reversed(lst):\n",
    "            del person['annopoints'][0]['point'][num]\n",
    "                \n",
    "json.dump({'annolist' : ans_list }, open(db_type+'_multi.json', 'w'))\n",
    "\n",
    "inds = []\n",
    "for i in range(len(is_multi)): \n",
    "    if is_multi[i]:\n",
    "        inds.append(ids[i])\n",
    "\n",
    "print(inds, file=open(db_type+'_multi_inds.txt', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
